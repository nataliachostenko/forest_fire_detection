{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe92410-60c3-4742-97c9-a9e8e035c466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: /app/data/Training and Validation/fire\n",
      "Loading images from: /app/data/Training and Validation/nofire\n",
      "Loaded 0 training images\n",
      "Loading images from: /app/data/Testing/fire\n",
      "Loading images from: /app/data/Testing/nofire\n",
      "Loaded 0 testing images\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in the specified directories. Please check the directory paths and contents.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 198\u001b[0m\n\u001b[1;32m    195\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_curve.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 198\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 58\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m testing images\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Diagnostyka\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_images) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_images) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found in the specified directories. Please check the directory paths and contents.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m     61\u001b[0m all_labels_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(all_labels)\n",
      "\u001b[0;31mValueError\u001b[0m: No images found in the specified directories. Please check the directory paths and contents."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score\n",
    "from torchvision import models, transforms\n",
    "\n",
    "def load_images_with_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in ['fire', 'nofire']:\n",
    "        path = os.path.join(folder, label)\n",
    "        print(f\"Loading images from: {path}\")  # Diagnostyka\n",
    "        for filename in glob(os.path.join(path, '*.jpg')):\n",
    "            img = cv2.imread(filename)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))  \n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def main():\n",
    "    data_dir = \"/Users/chostenko/Desktop/pbs/VI_semestr/uczenie_maszynowe/PROJ/forest_fire\"\n",
    "    train_dir = os.path.join(data_dir, 'Training and Validation')\n",
    "    test_dir = os.path.join(data_dir, 'Testing')\n",
    "\n",
    "    all_images, all_labels = load_images_with_labels(train_dir)\n",
    "    print(f\"Loaded {len(all_images)} training images\")  # Diagnostyka\n",
    "\n",
    "    test_images, test_labels = load_images_with_labels(test_dir)\n",
    "    print(f\"Loaded {len(test_images)} testing images\")  # Diagnostyka\n",
    "\n",
    "    if len(all_images) == 0 or len(test_images) == 0:\n",
    "        raise ValueError(\"No images found in the specified directories. Please check the directory paths and contents.\")\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_labels_encoded = label_encoder.fit_transform(all_labels)\n",
    "    test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "        all_images, all_labels_encoded, test_size=0.2, stratify=all_labels_encoded, random_state=42\n",
    "    )\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = CustomDataset(train_images, train_labels, transform=transform)\n",
    "    val_dataset = CustomDataset(val_images, val_labels, transform=transform)\n",
    "    test_dataset = CustomDataset(test_images, test_labels_encoded, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = models.vgg16(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.classifier[6] = nn.Linear(4096, 2)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.classifier[6].parameters(), lr=0.0001)\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    num_epochs = 10\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_epoch_accuracy = val_correct / val_total\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}, \"\n",
    "              f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.4f}\")\n",
    "\n",
    "    print(\"Training complete\")\n",
    "\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "    test_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "\n",
    "    print(classification_report(all_labels, all_predictions, target_names=label_encoder.classes_))\n",
    "\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred_proba = np.array(all_probs)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "    print(f'ROC-AUC: {roc_auc}')\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba[:, 1])\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2f5cd-6be5-4a2c-8f3a-7c1828be2557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
